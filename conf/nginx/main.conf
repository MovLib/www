# ----------------------------------------------------------------------------------------------------------------------
# This file is part of {@link https://github.com/MovLib MovLib}.
#
# Copyright © 2013-present {@link http://movlib.org/ MovLib}.
#
# MovLib is free software: you can redistribute it and/or modify it under the terms of the GNU Affero General Public
# License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later
# version.
#
# MovLib is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty
# of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Affero General Public License for more details.
#
# You should have received a copy of the GNU Affero General Public License along with MovLib.
# If not, see {@link http://www.gnu.org/licenses/ gnu.org/licenses}.
# ----------------------------------------------------------------------------------------------------------------------

# ----------------------------------------------------------------------------------------------------------------------
# Nginx core configuration.
#
# How this file is organized: We are mainly using the official documentation for each option. This should help users to
# understand each option without starting to search for the directives. For more complex directives (or even
# undocumented ones) we write up something or quote another web resource. Always check the provided link for the source.
#
# Options are ordered alphabetically within their sections and sections are also ordered alphabetically.
#
# AUTHOR: Richard Fussenegger <richard@fussenegger.info>
# COPYRIGHT: © 2013-present, MovLib
# LICENSE: http://www.gnu.org/licenses/agpl.html AGPL-3.0
# SINCE: 0.0.1-dev
# ----------------------------------------------------------------------------------------------------------------------

# Enables or disables the use of “just-in-time compilation” (PCRE JIT) for regular expressions known at configuration
# parse time.
#
# PCRE JIT can speed up processing of regular expressions significantly.
#
# The JIT is available in PCRE libraries starting from version 8.20 built with the --enable-jit configuration parameter.
# When building the PCRE library with nginx (--with-pcre=), the JIT support should be enabled with the --with-pcre-jit
# configuration parameter.
#
# NOTE:      Requires PCRE library >=8.20
# SYNTAX:    pcre_jit on | off;
# DEFAULT:   off
# SINCE:     1.1.12
# LINK:      http://nginx.org/en/docs/ngx_core_module.html#pcre_jit
# LINK:      http://www.pcre.org/
pcre_jit on;

# Reduces timer resolution in worker processes, thus reducing the number of gettimeofday() system calls made. By
# default, gettimeofday() is called each time on receiving a kernel event. With reduced resolution, gettimeofday() is
# only called once per specified interval.
#
# SYNTAX:    timer_resolution interval;
# LINK:      http://nginx.org/en/docs/ngx_core_module.html#timer_resolution
timer_resolution 100ms;

# Defines user and group credentials used by worker processes. If group is omitted, a group whose name equals that of
# user is used.
#
# SYNTAX:     user user [group];
# DEFAULT:    nobody nobody
# LINK:       http://nginx.org/en/docs/ngx_core_module.html#user
user www-data www-data;

# Binds worker processes to the sets of CPUs. Each CPU set is represented by a bitmask of allowed to use CPUs. There
# should be a separate set defined for each of the worker processes. By default, worker processes are not bound to any
# specific CPUs.
#
# For example,
#
#    worker_processes    4;
#    worker_cpu_affinity 0001 0010 0100 1000;
#
# binds each worker process to a separate CPU, while
#
#    worker_processes    2;
#    worker_cpu_affinity 0101 1010;
#
# binds the first worker process to CPU0/CPU2, and the second worker process to CPU1/CPU3. The second example is
# suitable for hyper-threading.
#
# NOTE:       The directive is only available on FreeBSD and Linux.
# SYNTAX:     worker_cpu_affinity cpumask ...;
# LINK:       http://nginx.org/en/docs/ngx_core_module.html#worker_cpu_affinity
worker_cpu_affinity

# Defines a scheduling priority for worker processes like is done by the nice command: a negative number means higher
# priority. Allowed range normally varies from -20 to 20.
#
# SYNTAX:     worker_priority number;
# DEFAULT:    0
# LINK:       http://nginx.org/en/docs/ngx_core_module.html#worker_priority
worker_priority -10;

# Defines the number of worker processes.
#
# The optimal value depends on many factors including (but not limited to) the number of CPU cores, the number of hard
# disk drives that store data, and load pattern. When in doubt, setting it to the number of available CPU cores would be
# a good start (the value "auto" will try to autodetect it).
#
# More in depth explanation taken from calomel.org:
#
# Is the number of worker processes to spawn. A worker is similar to a child process in Apache. Nginx has the ability to
# use more then one worker process for several reasons: use on (SMP) multiple processors machines, to decrease latency
# when workers are blocked by disk I/O, or to limit the number of connections per process when select() or poll() is
# used. The general rule of the thumb is to set the number of nginx workers to at least two(2) or the number of CPUs
# your server has; which ever is greater. Our example nginx.conf has 3 workers on a 4 core box.
#
# For testing, we suggest using the httperf or Apache benchmark binary (ab) to stress your server and see how many
# connections your machine can handle. "ab" can be found in any apache_utils install and httperf is a stand alone
# package. To calculate how many total concurrent connections nginx can support, multiply "worker_processes" times
# "worker_connections". Our example is setup to handle 3*64=192 total concurrent connections. Clients who attempt to
# connect after 192 concurrent clients are already connected will be denied access. It is better to deny clients than
# overload the machine possibly causing a DOS. Make sure not to set these values to high as your machine might just
# crumble under the strain of too many clients. Take a look for our httperf testing procedure lower down on this page.
#
# SYNTAX:     worker_processes number | auto;
# DEFAULT:    1
# SINCE:      1.2.5 | 1.3.8 - Support for auto setting
# LINK:       http://nginx.org/en/docs/ngx_core_module.html#worker_processes
# LINK:       https://calomel.org/nginx.html
worker_processes auto;

# Changes the limit on the largest size of a core file (RLIMIT_CORE) for worker processes. Used to increase the limit
# without restarting the main process.
#
# SYNTAX:     worker_rlimit_core
# LINK:       http://nginx.org/en/docs/ngx_core_module.html#worker_rlimit_core
#worker_rlimit_core size;

# Changes the limit on the maximum number of open files (RLIMIT_NOFILE) for worker processes. Used to increase the limit
# without restarting the main process.
#
# More in depth explanation taken from calomel.org:
#
# Is the maximum number file descriptors (ulimit -n) that can be opened by EACH worker_processes. In the case of Nginx
# this translates to the amount of open network connections to remote clients in addition to proxied backend connections.
# Understand that the open file limit is really regulated by the operating system. This directive simply allows Nginx to
# try to set "ulimit -n value" when nginx starts. When you set this directive you will not need to set a separate
# "ulimit -n 'value' " in the OS. Default value (the ulimit -n value) will be overridden. If worker_rlimit_nofile is not
# specified, your default ulimit -n number for the user who is running nginx will take effect. It is very important to
# note the worker_rlimit_nofile value should be greater or equal to worker_connections. If your open file limit is too
# low for the amount of connections nginx is making you will see the error, "Too many open files" in the error log. For
# example, OpenBSD has a really low open file limit of 128 files for a normal user; i.e. not root. You will want to set
# this directive to at least 1024 to avoid errors. You will also want to make sure that if you are keeping connections
# open for a long time with keepalive statements to watch this value. Each open connection is a used open file descriptor
# and thus counts against your "ulimit -n" value.
#
# NOTE:       Value should be power of 2.
# SYNTAX:     worker_rlimit_nofile number;
# LINK:       http://nginx.org/en/docs/ngx_core_module.html#worker_rlimit_nofile
# LINK:       https://calomel.org/nginx.html
worker_rlimit_nofile 262144;

# On systems that support rtsig connection processing method, changes the limit on the number of signals that may be
# queued (RLIMIT_SIGPENDING) for worker processes. Used to increase the limit without restarting the main process.
#
# NOTE:       DO NOT USE rtsig! epoll is much more efficient.
# SYNTAX:     worker_rlimit_sigpending number;
# CONTEXT:    main
# LINK:       http://nginx.org/en/docs/ngx_core_module.html#worker_rlimit_sigpending
#worker_rlimit_sigpending number;

# Defines a current working directory for a worker process. It is primarily used when writing a core-file, in which case
# a worker process should have write permission for the specified directory.
#
# SYNTAX:     working_directory directory;
# LINK:       http://nginx.org/en/docs/ngx_core_module.html#working_directory
#working_directory directory;
